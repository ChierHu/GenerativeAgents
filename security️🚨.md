# Security/Hacking 安全/黑客

TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent Constitution (2025)
https://breznikar.com/article/trustagent-towards-safe-and-trustworthy-llm-based-agents-through-agent-constitution/4397

AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection
https://arxiv.org/abs/2502.11448

G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems
https://arxiv.org/abs/2502.11127

CORBA: Contagious Recursive Blocking Attacks on Multi-Agent Systems Based on Large Language Models
https://arxiv.org/abs/2502.14529

Preventing Rogue Agents Improves Multi-Agent Collaboration
https://arxiv.org/abs/2502.05986

VulnBot: Autonomous Penetration Testing for A Multi-Agent Collaborative Framework
https://arxiv.org/abs/2501.13411

Infecting LLM Agents via Generalizable Adversarial Attack
https://openreview.net/forum?id=udsmFGMwlp

Towards Action Hijacking of Large Language Model-based Agent
https://arxiv.org/abs/2412.10807

TrendSim: Simulating Trending Topics in Social Media Under Poisoning Attacks with LLM-based Multi-agent System
https://arxiv.org/abs/2412.12196

Targeting the Core: A Simple and Effective Method to Attack RAG-based Agents via Direct LLM Manipulation
https://arxiv.org/abs/2412.04415

NeuroAI for AI Safety
https://arxiv.org/abs/2411.18526

Navigating the Risks: A Survey of Security, Privacy, and Ethics Threats in LLM-Based Agents
https://arxiv.org/abs/2411.09523

CTIKG: LLM-Powered Knowledge Graph Construction from Cyber Threat Intelligence
https://openreview.net/forum?id=DOMP5AgwQz#discussion

Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games
https://arxiv.org/abs/2403.17674

Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks
https://arxiv.org/abs/2310.10844

Evil Geniuses: Delving into the Safety of LLM-based Agents
https://arxiv.org/abs/2311.11855

## Verification 验证
Speaker Verification in Agent-Generated Conversations
https://arxiv.org/abs/2405.10150

## Adversarial 对抗
Red-Teaming LLM Multi-Agent Systems via Communication Attacks
https://arxiv.org/abs/2502.14847

## Benchmark 基准
Ollabench: Evaluating LLMs' Reasoning for Human-centric Interdependent Cybersecurity
https://arxiv.org/abs/2406.06863

Identifying the Risks of LM Agents with an LM-Emulated Sandbox
https://arxiv.org/abs/2309.15817

## Phish 钓鱼
PhishAgent: A Robust Multimodal Agent for Phishing Webpage Detection
https://arxiv.org/abs/2408.10738

Automated Phishing Detection Using URLs and Webpages
https://arxiv.org/abs/2408.01667

Simulation Tests in Anti-phishing Training
https://link.springer.com/chapter/10.1007/978-3-031-56599-1_12

## Incident Response 事件响应
Multi-Agent Collaboration in Incident Response with Large Language Models
https://arxiv.org/abs/2412.00652

Schema-Guided Culture-Aware Complex Event Simulation with Multi-Agent Role-Play
https://arxiv.org/abs/2410.18935

## Penetration 渗透
HackSynth: LLM Agent and Evaluation Framework for Autonomous Penetration Testing
https://arxiv.org/abs/2412.01778

AutoPenBench: Benchmarking Generative Agents for Penetration Testing
https://arxiv.org/abs/2410.03225

Getting pwn’d by AI: Penetration Testing with Large Language Models
Authors: Andreas Happe, Jürgen CitoAuthors Info & Claims
https://dl.acm.org/doi/abs/10.1145/3611643.3613083

## Vulnerability 漏洞
YuraScanner: Leveraging LLMs for Task-driven Web App Scanning
https://publications.cispa.de/articles/conference_contribution/YuraScanner_Leveraging_LLMs_for_Task-driven_Web_App_Scanning/27993545?file=51062570

## Jailbreak 越狱
A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns
https://arxiv.org/abs/2410.16155

RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent
https://arxiv.org/abs/2407.16667

## Fake News/Rumors 假新闻/谣言
From a Tiny Slip to a Giant Leap: An LLM-Based Simulation for Fake News Evolution
https://arxiv.org/abs/2410.19064

Large Language Model-driven Multi-Agent Simulation for News Diffusion Under Different Network Structures
https://arxiv.org/abs/2410.13909

## Fact-Checking 事实核查
FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models
https://arxiv.org/abs/2502.17924

## Trustworthiness 可信度
On the Trustworthiness of Generative Foundation Models: Guideline, Assessment, and Perspective
https://arxiv.org/abs/2502.14296

## Network Security 网络安全
Hackphyr: A Local Fine-Tuned LLM Agent for Network Security Environments
https://arxiv.org/abs/2409.11276

## Deception 欺骗
Deception in Reinforced Autonomous Agents
https://arxiv.org/abs/2405.04325

Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation
https://arxiv.org/abs/2310.01320

## Watermarking 水印
Inaccessible Entropy for Watermarking Generative Agents
https://eprint.iacr.org/2025/256

## botnet 僵尸网络
Anatomy of an AI-powered malicious social botnet
https://arxiv.org/abs/2307.16336

## Embodied AI 具身智能
Towards Robust and Secure Embodied AI: A Survey on Vulnerabilities and Attacks
https://arxiv.org/abs/2502.13175
## Catastrophic Risks 灾难性风险
"Nuclear Deployed!": Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents
https://arxiv.org/abs/2502.11355
