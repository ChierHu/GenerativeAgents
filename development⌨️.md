# Coding/Programming/Software Development 代码/编程/软件开发

Improving Performance of Commercially Available AI Products in a Multi-Agent Configuration
https://arxiv.org/abs/2410.22129

Large Language Model Guided Self-Debugging Code Generation
https://arxiv.org/abs/2502.02928

MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework
https://arxiv.org/abs/2308.00352

OpenHands: An Open Platform for AI Software Developers as Generalist Agents
https://arxiv.org/abs/2407.16741

Tree-of-Code: A Tree-Structured Exploring Framework for End-to-End Code Generation and Execution in Complex Task Handling
https://arxiv.org/abs/2412.15305

Reasoning and Planning with Large Language Models in Code Development
https://dl.acm.org/doi/abs/10.1145/3637528.3671452

Integrating Artificial Intelligence (AI) in Software Development
Inventor(s)
https://www.tdcommons.org/dpubs_series/7088/

LLM-MA(Large Language Model Multi Agent)를 활용한 소프트웨어 개발에 대한 연구 동향 분석
https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11891113

GOEX: PERSPECTIVES AND DESIGNS TOWARDS A RUNTIME FOR AUTONOMOUS LLM APPLICATIONS
https://storage.prod.researchhub.com/uploads/papers/2024/04/24/2404.06921.pdf

Communicative Agents for Software Development
https://openreview.net/pdf?id=yW0AZ5wPji
https://arxiv.org/pdf/2307.07924

ChatDev: Communicative Agents for Software Development
https://arxiv.org/abs/2307.07924

AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation
https://arxiv.org/abs/2312.13010

## Testing 测试
Towards Autonomous Testing Agents via Conversational Large Language Models
https://ieeexplore.ieee.org/abstract/document/10298360?casa_token=_RDxK66AsYwAAAAA:MZo4Dfy1tJ9wNRqjL45UKBWC2UqRjp7cLIXJ86kAai_Kq-3lyIFS4_jloweO7YJIalof1J0U0uOPtSg

## Process 流程
Think-on-Process: Dynamic Process Generation for Collaborative Development of Multi-Agent System
https://arxiv.org/abs/2409.06568

## Alignment 对齐
AltDev: Achieving Real-Time Alignment in Multi-Agent Software Development
https://openreview.net/forum?id=lVUuQhjbRd

## code evaluation 代码评估
Can Large Language Models Serve as Evaluators for Code Summarization?
https://arxiv.org/abs/2412.01333

Auto-Enhance: Towards a Meta-Benchmark to Evaluate AI Agents' Ability to Improve Other Agents
https://openreview.net/forum?id=YAhyaNEoy9

PyBench: Evaluating LLM Agent on various real-world coding tasks
https://arxiv.org/abs/2407.16732

## Observability 可观察性
Watson: A Cognitive Observability Framework for the Reasoning of Foundation Model-Powered Agents
https://arxiv.org/abs/2411.03455

## Assistants 助手
Need Help? Designing Proactive AI Assistants for Programming
https://arxiv.org/abs/2410.04596

## UI
Generating Automatic Feedback on UI Mockups with Large Language Models
https://dl.acm.org/doi/full/10.1145/3613904.3642782
